# Offroad Segmentation Scripts — Development Log

> This folder contains the **original development scripts** used during the hackathon. These are the raw working files where all 3 training phases were developed, debugged, and iterated on. Clean, renamed copies are in `TRAINING_SCRIPTS/` at the project root.

---

## File Timeline & Usage

### 1. `train_segmentation.py` — Phase 1 Baseline (Day 1)

> **When**: First file used. The hackathon-provided starter script.  
> **Role**: Ran as-is without any modifications to establish the baseline IoU of **0.2971**.  
> **Key details**:
>
> - DINOv2 ViT-Small backbone (frozen) + ConvNeXt segmentation head
> - SGD optimizer (lr=1e-4), no scheduler, no augmentations
> - 10 epochs, batch_size=2, 476×266 resolution
> - Output went to `train_stats/` subfolder (baseline training curves)
>
> **Copied to**: `TRAINING_SCRIPTS/train_phase1_baseline.py`

---

### 2. `train_improved.py` — Phase 2 Improved (Day 1-2)

> **When**: Created after analyzing Phase 1 results. Built from scratch using `train_segmentation.py` as reference.  
> **Role**: Addressed Phase 1's underfitting with better optimization and data handling. Achieved IoU = **0.4036**.  
> **Key changes from Phase 1**:
>
> - AdamW optimizer + CosineAnnealingLR scheduler
> - Albumentations pipeline (HFlip, VFlip, ShiftScaleRotate, Blur, ColorJitter)
> - Weighted CrossEntropyLoss (class weights from pixel frequency)
> - Mixed precision (AMP), best model checkpointing, early stopping
> - 30 epochs
>
> **Bugs fixed during development**:
>
> - `RandomRotate90` crashed DataLoader on non-square images (dimension swap broke `torch.stack`) — **removed**
> - Augmentation/normalization split across two pipelines caused inconsistency — **unified into one pipeline**
>
> **Copied to**: `TRAINING_SCRIPTS/train_phase2_improved.py`

---

### 3. `train_phase3.py` — Phase 3 Advanced (Day 2-3)

> **When**: Created after Phase 2 plateaued at 0.40. Complete architectural overhaul.  
> **Role**: The most advanced script. Achieved IoU = **0.5161** — our best result.  
> **Key changes from Phase 2**:
>
> - DINOv2 ViT-Base backbone (768-dim, 2× richer than ViT-Small)
> - UPerNet segmentation head (PPM + multi-scale FPN with dilated convolutions)
> - Focal Loss (γ=2) + Dice Loss combo (replaces weighted CE)
> - Higher resolution: 644×364 (84% more pixels)
> - Gradient accumulation (effective batch=4)
> - 3-epoch warmup + CosineAnnealing scheduler
> - GroupNorm (replaced BatchNorm to fix PPM 1×1 spatial crash)
> - RandomShadow + CLAHE augmentations added
> - 40 epochs
>
> **Bugs fixed during development**:
>
> - `BatchNorm2d` crashed when PPM's `AdaptiveAvgPool2d(1)` created 1×1 spatial tensors — **replaced with GroupNorm**
>
> **Copied to**: `TRAINING_SCRIPTS/train_phase3_advanced.py`

---

### 4. `test_segmentation.py` — Inference Script

> **When**: Provided with hackathon starter kit, used after each training phase.  
> **Role**: Runs the best model on unseen test images from `Offroad_Segmentation_testImages/`.
>
> - Loads `segmentation_head.pth` (head-only weights)
> - Applies same preprocessing as training (resize, normalize)
> - Produces colored segmentation masks for visual inspection
>
> **Copied to**: `TRAINING_SCRIPTS/test_segmentation.py`

---

### 5. `visualize.py` — Visualization Helpers

> **When**: Provided with hackathon starter kit.  
> **Role**: Utility functions for overlaying predictions on images and generating side-by-side comparisons.
>
> **Copied to**: `TRAINING_SCRIPTS/visualize.py`

---

### 6. `segmentation_head.pth` — Best Model Weights (9.3 MB)

> **When**: Generated by `train_phase3.py` at the end of Phase 3 training.  
> **Role**: Head-only weights (UPerNet parameters only, no optimizer state). This is the file that `test_segmentation.py` loads for inference.
>
> - Extracted from Phase 3's `best_model.pth` (full checkpoint with optimizer = 39MB)
> - Contains only the segmentation head state_dict (9.3MB)
>
> **Also copied to**: `MODELS/segmentation_head.pth`

---

## Subfolders

### `train_stats/`

Early Phase 1 baseline output — training curve plots and metrics generated by `train_segmentation.py`:

- `all_metrics_curves.png` — 2×2 grid of Loss, IoU, Dice, Accuracy
- `iou_curves.png` — IoU train/val curves
- `dice_curves.png` — Dice train/val curves
- `training_curves.png` — Loss train/val curves
- `evaluation_metrics.txt` — Per-epoch metrics table

These are the same outputs that were later copied to `TRAINING AND PROGRESS/PHASE_1_BASELINE/`.

### `ENV_SETUP/`

Early environment setup batch scripts (superseded by `ENV_SETUP/` at project root):

- `create_env.bat` — Creates Python virtual environment
- `install_packages.bat` — Installs PyTorch + dependencies
- `setup_env.bat` — Combined setup script

These were the first iteration of our setup automation. The cleaner versions at `ENV_SETUP/setup_env.bat` and `ENV_SETUP/setup_env.sh` replaced them.

---

## Development Flow

```
Day 1:  train_segmentation.py → Phase 1 baseline (IoU=0.2971)
          ↓ analyzed results, found underfitting
Day 1-2: train_improved.py → Phase 2 improved (IoU=0.4036)
          ↓ hit architectural ceiling, single-scale head bottleneck
Day 2-3: train_phase3.py → Phase 3 advanced (IoU=0.5161)
          ↓ best model saved as segmentation_head.pth
Day 3:   test_segmentation.py → inference on test images
```
